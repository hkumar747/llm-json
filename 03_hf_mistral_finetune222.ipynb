{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkumar747/llm-json/blob/main/03_hf_mistral_finetune222.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JujnHObVWeP5"
      },
      "source": [
        "# Parameter efficient fine-tuning Mistral-7b\n",
        "\n",
        "### Using Quantized LoRA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkhsiPd8WeP6"
      },
      "source": [
        "## Use case: We need a customized model for extracting structured data from permit notices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXciMxfSWeP7",
        "outputId": "2a316dff-d9c3-463d-bec2-a56eaf3660a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#  !pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
        "# https://blog.paperspace.com/mistral-7b-fine-tuning/\n",
        "# !pip install transformers trl langchain accelerate torch bitsandbytes peft datasets -qU\n",
        "# !pip install -q datasets loralib sentencepiece xformers einops\n",
        "!pip install -q -U peft==0.6.2 transformers==4.35.2 datasets==2.15.0 bitsandbytes==0.41.2.post2 trl==0.7.4 accelerate==0.24.1 wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og9IkSzFWeP7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSaqydFWeP7"
      },
      "source": [
        "## Parameter Efficient Fine Tuning with LoRA\n",
        "\n",
        "\n",
        "https://heidloff.net/article/efficient-fine-tuning-lora/\n",
        "\n",
        "https://towardsdatascience.com/implementing-lora-from-scratch-20f838b046f1\n",
        "\n",
        "`verbatim`\n",
        "PEFT, or Parameter-Efficient Fine-Tuning (PEFT), is a library for efficiently adapting pre-trained language models to downstream applications without without the need to re-train or fine-tune all the parameters.\n",
        "\n",
        "One main form of PEFT is Low Rank Adaptation (LoRA) of large language models, based on the concept of rank of matrices in linear algebra.\n",
        "\n",
        "```\n",
        "LoRA is a method for fine-tuning language models without altering the original model parameters. In practical fine-tuning tasks, a set of low-rank adapters is added alongside specific model layers to be trained. In the original paper, the adapters were only added to two attention layers. The output dimensions of these adapters match those of the original model layers exactly.\n",
        "\n",
        "Subsequently, the adapters are set to be trainable, while the original model parameters are frozen and not allowed to be trained. This approach allows for the training of large language models without affecting inference speed significantly and only slightly increasing the parameter count.\n",
        "```\n",
        "\n",
        "\n",
        "\"common pre-trained models have a very low intrinsic dimension; in other words, there exists a low dimension reparameterization that is as effective for fine-tuning as the full parameter space.\"\n",
        "https://arxiv.org/abs/2012.13255\n",
        "\n",
        "\n",
        "Instead of adjusting the entire weight matrix (which is part of the linear transformations in the model's layers), LoRA introduces additional low-rank matrices that modify the original weight matrices in a more parameter-efficient manner. This process allows for targeted adaptations that significantly alter the model's behavior\n",
        "\n",
        "\n",
        "<img src=\"images/peft_heidloff.png\" alt=\"Descriptive text about the image\" width=\"600\"/>\n",
        "\n",
        "Source: [Niklas Heidloff](https://heidloff.net/article/efficient-fine-tuning-lora/)\n",
        "\n",
        "\n",
        "**SVD and matrix rank**\n",
        "https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html\n",
        "\"The overall idea and concept are related to principal component analysis (PCA) and singular value decomposition (SVD), where we approximate a high-dimensional matrix or dataset using a lower-dimensional representation. In other words, we try to find a (linear) combination of a small number of dimensions in the original feature space (or matrix) that can capture most of the information in the dataset.\"\n",
        "\n",
        "**Remember:** Large Language Models (LLMs) are simply lots of matrices (or tensors) of numbers.\n",
        "\n",
        "\n",
        "\n",
        "**PEFT supported models**\n",
        "\n",
        "HuggingFace has a list of 10 models for which LoRA adapters are available:\n",
        "https://huggingface.co/docs/peft/index#supported-models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1xcNvN0WeP8"
      },
      "source": [
        "## Selecting a model\n",
        "\n",
        "\n",
        "Look at the [HF leaderboard of open LLMS](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\n",
        "\n",
        "There are multiple benchmarks to score LLMs, each designed for different linguistic, reasoning or numeric tasks.\n",
        "\n",
        "\n",
        "**Benchmarks:**\n",
        "\n",
        "\n",
        "**1. ARC (AI2 Reasoning Challenge)**\n",
        "ARC challenges models on grade-school level multiple-choice science questions. It's designed to test a model's reasoning and knowledge.\n",
        "\n",
        "\n",
        "**2. HellaSwag**\n",
        "HellaSwag is a benchmark for commonsense reasoning, predicting the endings of a given scenario in both textual and video contexts.\n",
        "\n",
        "\n",
        "**3. MMLU (Massive Multitask Language Understanding)**\n",
        "MMLU evaluates language models across a wide range of subjects and disciplines, testing the model's understanding on diverse topics.\n",
        "\n",
        "**4. TruthfulQA**\n",
        "This benchmark tests models on providing truthful answers, focusing on avoiding hallucinations and sticking to factual responses.\n",
        "\n",
        "\n",
        "**5. Winogrande**\n",
        "Winogrande is a dataset for commonsense reasoning, designed as an improved and scaled-up version of the Winograd Schema Challenge.\n",
        "\n",
        "\n",
        "**6. GSM8K (Grade School Math 8K)**\n",
        "GSM8K tests models on solving grade-school level math problems presented in textual form.\n",
        "\n",
        "\n",
        "Without admittedly delving too deep into it (maybe one of the above benchmarks has JSON tasks), common-sense reasoning would say TruthfulQA is the most relevant benchmark for this task. It mostly doesn't require any external knowledge of the world (caveat: impacts on wetland), just the ability to not hallucinate or be inaccurate when it transcribes from the text to the dictionary.\n",
        "\n",
        "In any case, we will be fine-tuning the Mistral-7b model.\n",
        "\n",
        "The following resources are helpful for understanding this notebook:\n",
        "\n",
        "- [Mistral](https://www.datacamp.com/tutorial/mistral-7b-tutorial)\n",
        "\n",
        "- [Mixtral](https://github.com/brevdev/notebooks/blob/main/mixtral-finetune-own-data.ipynb)\n",
        "\n",
        "- [huggingFace Transformers Training](https://huggingface.co/docs/transformers/en/training)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20vqKfY6WeP8"
      },
      "source": [
        "### Weights & Biases for tracking metrics\n",
        "\n",
        "Use Weights & Biases to track training metrics. Enter your API key when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nieXrYd9WeP8",
        "outputId": "502c057d-c28a-4de0-db02-30dcd016cda1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wandb -U\n",
        "\n",
        "import wandb, os\n",
        "wandb.login()\n",
        "\n",
        "wandb_project = \"mistral-7b-usace-finetune_v2\"\n",
        "os.environ[\"WANDB_PROJECT\"] = wandb_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1Y9s4TWeP8"
      },
      "source": [
        "## Load training dataset\n",
        "\n",
        "It just needs to be a dataset of input-output pairs. The phrase 'supervised fine tuning' signals an image of a dataset of (vectors) of inputs and output, as in supervised learning. But that would be misleading - here the Xs and Ys are concatenated together into strings of continuous tokens, interspersed with special tokens which marks inputs and outputs.\n",
        "\n",
        "Basically, the dataset consists of input-output pairs like:\n",
        "\n",
        "**Input**\n",
        ">The applicant seeks author ization to construct a single-family residence on the 2.09-acre parcel, including the permanent fill and loss of  0.78 acres of mangrove wetlands.\n",
        "\n",
        "\n",
        "**Output**\n",
        ">\n",
        "\n",
        ">>{'wetlands': [\n",
        ">  {'**wetland_type**': 'mangrove wetlands',\n",
        "\n",
        "> >  '**impact_quantity**': 0.78,\n",
        "\n",
        " > > '**impact_unit**': 'acres',\n",
        "\n",
        "  > >'**impact_type**': 'fill',\n",
        "   \n",
        "   >> '**impact_duration**': 'permanent'}]}\n",
        ">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjLSuyJEWeP8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "instruct_tune_dataset = load_dataset(\"mosaicml/instruct-v3\")\n",
        "instruct_tune_dataset\n",
        "\n",
        "type(instruct_tune_dataset)\n",
        "\n",
        "instruct_tune_dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSm5u7UuWeP8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcuNqCiUWeP9"
      },
      "source": [
        "\n",
        "### Convert from OpenAI JSONL to HuggingFace Dataset\n",
        "\n",
        "https://huggingface.co/transformers/v3.2.0/custom_datasets.html\n",
        "\n",
        "\n",
        "Load the JSONL file of verified input-output pairs we used in notebook 2. (This step assumes you've already connverted them into JSONL format for OpenAI.) The following step will convert these into a format suitable for HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4onOYkfNWeP9",
        "outputId": "9550b8f5-3560-41f2-c3d9-992e27e94348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "Dataset({\n",
            "    features: ['system', 'user', 'assistant'],\n",
            "    num_rows: 88\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from pathlib import Path\n",
        "import json\n",
        "def load_jsonl_to_dataset(jsonl_file_path):\n",
        "    # Initialize lists to hold the values for each field\n",
        "    system_messages = []\n",
        "    user_messages = []\n",
        "    assistant_messages = []\n",
        "\n",
        "    # Open and read the JSONL file\n",
        "    with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            data = json.loads(line)\n",
        "            system_msg = user_msg = assistant_msg = None  # Reset for each entry\n",
        "\n",
        "            # Iterate over messages and extract content based on role\n",
        "            for message in data['messages']:\n",
        "                if message['role'] == 'system':\n",
        "                    system_msg = message['content']\n",
        "                elif message['role'] == 'user':\n",
        "                    user_msg = message['content']\n",
        "                elif message['role'] == 'assistant':\n",
        "                    assistant_msg = message['content']\n",
        "\n",
        "            # Append messages to their respective lists\n",
        "            system_messages.append(system_msg)\n",
        "            user_messages.append(user_msg)\n",
        "            assistant_messages.append(assistant_msg)\n",
        "\n",
        "    # Construct a dictionary with these lists\n",
        "    data_dict = {\n",
        "        'system': system_messages,\n",
        "        'user': user_messages,\n",
        "        'assistant': assistant_messages\n",
        "    }\n",
        "\n",
        "    # Convert the dictionary to a Hugging Face Dataset\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset = load_jsonl_to_dataset(\"usace_finetune_training.jsonl\")\n",
        "val_dataset = load_jsonl_to_dataset(\"usace_finetune_validation.jsonl\")\n",
        "\n",
        "# Displaying the structure of the train dataset as an example\n",
        "print(f\"Train Dataset:\\n{train_dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instruction:"
      ],
      "metadata": {
        "id": "zQNbI3vMiJsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]['system']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "hiCX8acRiAWr",
        "outputId": "cff41d19-ea5c-4675-9645-0c2929ea82dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\\n\\nJSON Schema Overview:\\n\\nwetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\\nimpact_quantity: Numeric value of the impacted area.\\nimpact_unit: Units of measurement (acres, sq. feet, linear feet).\\nimpact_duration: Duration of impact (permanent, temporary, unknown).\\nimpact_type: Nature of impact (harmful, beneficial, unknown).\\nInstructions:\\n\\nIdentify Wetlands and Impacts: Look for sentences detailing the wetland type and area impacted. Record the type, quantity, and unit.\\nDetermine Impact Duration: Mark \\'permanent\\' or \\'temporary\\' if mentioned with wetland type and area; else, write \\'unknown\\'.\\nAssess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\\nAvoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\\nCreate a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\\nExample Input:\\n\\'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...\\'\\n\\nExpected Output:\\n{\\'wetlands\\': [{\\'wetland_type\\': \\'marshland\\', \\'impact_quantity\\': \\'3.5\\', \\'impact_unit\\': \\'acres\\', \\'impact_duration\\': \\'permanent\\', \\'impact_type\\': \\'loss\\'}]}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input:"
      ],
      "metadata": {
        "id": "o5xTgVnriNqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]['user']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "2Vf3uB0jiQgK",
        "outputId": "5f94e40a-9787-466c-ef59-55825cb57485"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Project Description: Clear, grade, excavate, and fill to construct a cemetery and funeral home.This project would require permanent impacts to 6.58 acres of forested palustrine wetlands. The applicant proposes to purchase credits from a mitigation bank to offset any unavoidable losses to wetland functions caused by project implementation.This is a second public notice due to changes in the project plans resulting in more wetland impacts than previously proposed.\\n\\nExtracted Data: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output"
      ],
      "metadata": {
        "id": "eXSSd21LiSXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset[5]['assistant']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FINCQZqYiTUd",
        "outputId": "86ca3ff4-e9a0-4bdd-d0f7-0d655fe90d09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"{'wetlands': [{'wetland_type': 'forested palustrine wetlands', 'impact_quantity': '6.58', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNj2dYzWeP9"
      },
      "source": [
        "### Prompt formatting function\n",
        "\n",
        "Change the prompt and output to the format specified for Mistral-7b - particularly, note the beginning of string (bos) and end of string (eos) special tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "dPjZcaLbWeP9",
        "outputId": "db1bf0af-af3b-4d3b-9a34-8d193f727fab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>### Instruction: \\n\"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.  JSON Schema Overview:  wetland_type: Type or descriptor of the wetland (e.g., swamp, marsh). impact_quantity: Numeric value of the impacted area. impact_unit: Units of measurement (acres, sq. feet, linear feet). impact_duration: Duration of impact (permanent, temporary, unknown). impact_type: Nature of impact (harmful, beneficial, unknown). Instructions:  Identify Wetlands and Impacts: Look for sentences detailing the wetland type and area impacted. Record the type, quantity, and unit. Determine Impact Duration: Mark \\'permanent\\' or \\'temporary\\' if mentioned with wetland type and area; else, write \\'unknown\\'. Assess Impact Type: Identify if the impact is harmful, beneficial, or unknown. Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts. Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format. Example Input: \\'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...\\'  Expected Output: {\\'wetlands\\': [{\\'wetland_type\\': \\'marshland\\', \\'impact_quantity\\': \\'3.5\\', \\'impact_unit\\': \\'acres\\', \\'impact_duration\\': \\'permanent\\', \\'impact_type\\': \\'loss\\'}]}\\n\\n### Input:\\nProject Description: Clear, grade, excavate, and fill to construct a cemetery and funeral home.This project would require permanent impacts to 6.58 acres of forested palustrine wetlands. The applicant proposes to purchase credits from a mitigation bank to offset any unavoidable losses to wetland functions caused by project implementation.This is a second public notice due to changes in the project plans resulting in more wetland impacts than previously proposed.  Extracted Data:\\n\\n### Response:\\n{\\'wetlands\\': [{\\'wetland_type\\': \\'forested palustrine wetlands\\', \\'impact_quantity\\': \\'6.58\\', \\'impact_unit\\': \\'acres\\', \\'impact_duration\\': \\'permanent\\', \\'impact_type\\': \\'loss\\'}]}</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def create_prompt(sample):\n",
        "    bos_token = \"<s>\"\n",
        "    eos_token = \"</s>\"\n",
        "\n",
        "    # Directly access the 'system', 'user', and 'assistant' messages from the sample\n",
        "    system_message = sample['system'].replace(\"\\n\", \" \").strip()\n",
        "    user_message = sample['user'].replace(\"\\n\", \" \").strip()\n",
        "    assistant_message = sample['assistant'].replace(\"\\n\", \" \").strip()\n",
        "\n",
        "    # Concatenate the prompt according to the specified format\n",
        "    full_prompt = f\"{bos_token}\"\n",
        "    full_prompt += f\"### Instruction: \\n{system_message}\"\n",
        "    full_prompt += f\"\\n\\n### Input:\\n{user_message}\"\n",
        "    full_prompt += f\"\\n\\n### Response:\\n{assistant_message}\"\n",
        "    full_prompt += f\"{eos_token}\"\n",
        "\n",
        "    return full_prompt\n",
        "create_prompt(train_dataset[5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlAObx1fWeP9"
      },
      "source": [
        "## Load and Train the Model\n",
        "\n",
        "https://blog.paperspace.com/mistral-7b-fine-tuning/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized LoRA (QLoRA)\n",
        "\n",
        "QLoRA by Dettmers et al., short for quantized LoRA, is a technique that reduces memory usage during finetuning. During backpropagation, QLoRA **quantizes** the pretrained weights to 4-bit precision and uses **paged optimizers** to handle memory spikes.\n",
        "\n",
        "**Democratization of AI**\n",
        "verbatim \"Traditionally, fine-tuning LLMs requires significant computing power and hardware resources, often inaccessible to researchers and smaller institutions. QLoRA bypasses this barrier by leveraging quantization, a process that reduces the size and complexity of LLM parameters. This makes fine-tuning more accessible and resource-efficient.\"https://wandb.ai/sauravmaheshkar/QLoRA/reports/What-is-QLoRA---Vmlldzo2MTI2OTc5\n",
        "\n",
        "\n",
        "This author found he saved 33% of GPU memory when using QLoRA, at a cost of 39% increased training runtime. This is caused by the additional quantization/dequantization steps of the pretrained model weights in QLoRA.\n",
        "\n",
        "Note: Its preferred to use BFloat16, but it wasn't supported on a V100 GPU on Colab, so I worked around this.\n",
        "\n",
        "https://brev.dev/blog/how-qlora-works\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qLtvHqmtj1pJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](qlora.png)"
      ],
      "metadata": {
        "id": "hU2b2gSRkNN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key idea: 4-Bit Normal Float\n",
        "4-bit NormalFloat or NF is a new information-theoretically optimal data type built on top of Quantile Quantization techniques. 4-Bit NF works by estimating the 2k + 1 (k is the number of bits) quantiles in a 0 to 1 distribution, then normalizing its values into the [-1, 1] range. Once we have that, we can also normalize our neural network weights into the [-1, 1] range and then quantize into the quantiles we got from step 2.\n",
        "\n",
        "‍https://www.mercity.ai/blog-post/guide-to-fine-tuning-llms-with-lora-and-qlora"
      ],
      "metadata": {
        "id": "aAA1JhQEjOjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "439a3cd68d8841ba8d25e06df00d1e6b",
            "4adf470dfa0f49c48c53064a865bcb5a",
            "a20123a902f24f0bbc397b9cbac8eebb",
            "afb1e86da43e47258a9ef6ebdbc6aa39",
            "40e78802b4f74370b0dc995b0dee84c2",
            "ff1ff7d15a0d4b2ea357ef183caa1202",
            "cebff71a8c394a40a69b8e51480d7018",
            "f0df51dc76a145ef902afbcba44186f2",
            "762f6cd0abd74f0389c2c52959217443",
            "bbb88499d3c9455b8c76154859c91f36",
            "0966b732e6a0437d8029f55f79f05b68",
            "129c92aea36a4837ae904cf52dfe63c5",
            "1f7ab46f77b540baaec090601ea4aa4d",
            "8fa0ccf77c6347fc8d62d835eef6df49",
            "ac62c6ddbd0f48e0b036cf5c6eeaeb82",
            "e33461eeaaab4a26ae54133d94f70ec2",
            "3885c0919e74436a8a5f29202212750d",
            "bdbcbac8af93406d91b857fefb6e998b",
            "54c98ad0f76548689e61bf41091f3830",
            "95c8b3e71bd747c8a360a0015157acd5",
            "446d79e223554d778f81927d1d8627b1",
            "136d148dd6e940b0ab8af675d832f53e",
            "d20fd6e4433d4dc8ab9199ccfd5b57a7",
            "61a4d79e24284d80b4659b8ff9faef8a",
            "73f7f15a68964bbf8fcb5a3404536cb2",
            "d770d4c60fad48ffa9dc45f7e7998490",
            "455a847eea3d4890880d0c803764f8b7",
            "eeba22ca47b84e138b7a191d82b19f63",
            "ca8be5f63af7420583d9924fc05f7cc7",
            "497f6ff3e2f14917be79e5eadee8a12f",
            "730d5fcc33ca4a829228f7fdbfbef425",
            "55d5a01145be4b89986f847626928b76",
            "d60b941f5265473d8fb865e46237260c",
            "30493cd8c368464885ac8b600353a56f",
            "6e4b4676db2f460d934ce9727976705f",
            "a5be4378fc6e4b4f98396d11b4d76930",
            "a9bea130bee14529ad72163dc244ea5e",
            "1cc27b234aa54f5f860f4ebbb54e9477",
            "42218085e56e490995412d663c6fe955",
            "0083cb563a1b4100871321a06176f802",
            "b6f6e7ac443b4a70a17395f588bfdaa9",
            "238a60a50c8c4193a3fba0c5581a8a7f",
            "6802efe69cc443a09f7facfb4cee9ce6",
            "ec98fe8d7b104ad0bd444e8955b7d5b6"
          ]
        },
        "id": "s0OoPwOHWeP9",
        "outputId": "01047e44-67e3-4cea-ff1e-b9bc8aa230ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "439a3cd68d8841ba8d25e06df00d1e6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "129c92aea36a4837ae904cf52dfe63c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d20fd6e4433d4dc8ab9199ccfd5b57a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30493cd8c368464885ac8b600353a56f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import transformers, accelerate, bitsandbytes\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# torch.set_default_device('cuda')\n",
        "\n",
        "# set quantization config\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "  #  bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "#select model\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "# \"stabilityai/stablelm-3b-4e1t\" - No quantization?\n",
        "\n",
        "# 'EleutherAI/gpt-neo-1.3B'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                              device_map='auto',\n",
        "                                              load_in_4bit=True,\n",
        "                                              quantization_config=nf4_config,\n",
        "                                              use_cache=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    #    padding_side=\"left\",\n",
        "    # add_eos_token=True,\n",
        "    # add_bos_token=True,\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hfHAK-dWeP-"
      },
      "source": [
        "## Step 3: Tokenization and padding\n",
        "\n",
        "Before training, you need to tokenize your dataset. The tokenizer will convert your text into a format that's suitable for the model to process:\n",
        "\n",
        "\n",
        "**Newline Characters**\n",
        "\n",
        "- When tokenizing text, newline characters are treated as whitespace and are used to separate tokens. For many models, especially those trained on a wide variety of internet text (like GPT, BERT, etc.), encountering newline characters is expected and won't cause issues.\n",
        "\n",
        "- For some tasks, newline characters might carry semantic meaning (e.g., separating paragraphs or items in a list), which could be relevant for the model to understand the structure of the input text.\n",
        "\n",
        "\n",
        "**Note:** Padding - affects compute requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rK_xntCWeP-"
      },
      "outputs": [],
      "source": [
        "\n",
        "token = \"\"\n",
        "\n",
        "# set max length of sequence\n",
        "max_length=968\n",
        "\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                     max_length=max_length,padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi3XoOuXWeP-"
      },
      "source": [
        "### Plot a histogram of the distribution of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS1p96AoWeP-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                     max_length=max_length,padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LRlghKhWeP-"
      },
      "source": [
        "## Set LoRA Configuration\n",
        "\n",
        "\n",
        "Choose the particular layers you want to fine tune - the more layers, the more the compute cost and training time, maybe for negligibly higher performance.\n",
        "\n",
        "As mentioned above, the original paper chose the $Q$ and $V$ layers of the attention mechanism.\n",
        "\n",
        "`r` = rank of the low-rank matrix used in the adapters. Changes the number of parameters trained. In the extreme, full rank would mean full fine-tuning\n",
        "\n",
        "`alpha` = scaling factor for the learned weights. The weight matrix is scaled by alpha/r, and thus a higher value for alpha assigns more weight to the LoRA activations.\n",
        "\n",
        "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbD-PCcbWeP-"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.08,\n",
        "    r=64,\n",
        "    target_modules=[\"q_proj\"],\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "    #     \"w1\",\n",
        "    #     \"w2\",\n",
        "    #     \"w3\",\n",
        "    #     \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-2zdpW0WeP-"
      },
      "outputs": [],
      "source": [
        "## prepare model for kbit training\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwJE9f2_WeP_"
      },
      "outputs": [],
      "source": [
        "# ONLY RUN this step to see the model - introduces errors\n",
        "\n",
        "\n",
        "model_print = get_peft_model(model, peft_config)\n",
        "model_print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWe4E1xWWeP_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4sWSumWWeP_"
      },
      "source": [
        "### How many trainable parameters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw6aG5JCWeP_"
      },
      "outputs": [],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRRWgP_KWeP_"
      },
      "source": [
        "### Training hyperparameters\n",
        "\n",
        "\n",
        "Use the `transformers` trainer. This is not the full list of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1S32hNWWeP_"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "args = TrainingArguments(\n",
        "  output_dir = \"mistral_instruct_generation\",\n",
        "  #num_train_epochs=5,\n",
        "  max_steps = 100,\n",
        "  per_device_train_batch_size = 1,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  # gradient_checkpointing = True,\n",
        "  fp16 = True,\n",
        "  # gradient_checkpointing_steps = 10,\n",
        "  warmup_steps = 0.03,\n",
        "  logging_steps=10,\n",
        "  save_strategy=\"epoch\",\n",
        "  #evaluation_strategy=\"epoch\",\n",
        "  evaluation_strategy=\"steps\",\n",
        "  eval_steps=40,\n",
        "  learning_rate=2e-4,\n",
        "  bf16=False,\n",
        "  lr_scheduler_type='constant',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFpMct-tWeP_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCLkkK_IWeP_"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "\n",
        "Use the huggingface `trl` module. Remember to replace create_prompt with the specific function for formatting prompts that you used above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6izISc-RWeP_"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 1024\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "  model=model,\n",
        "  peft_config=peft_config,\n",
        "  max_seq_length=max_seq_length,\n",
        "  tokenizer=tokenizer,\n",
        "  packing=True,\n",
        "  formatting_func=create_prompt,\n",
        "  args=args,\n",
        "  dataset_text_field=\"text\",\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset= val_dataset,\n",
        "  # instruct_tune_dataset[\"test\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbocXORGWeP_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "print(time.time()- start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iTxUbvRWeQA"
      },
      "source": [
        "### Save trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvXUpYB5WeQA"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "trainer.model.save_pretrained(\"mistral_ft_8mar\")\n",
        "wandb.finish()\n",
        "model.config.use_cache = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziY19sqAWeQA"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DztoyBh3WeQA"
      },
      "outputs": [],
      "source": [
        "# logging.set_verbosity(logging.CRITICAL)\n",
        "from transformers import pipeline\n",
        "prompt = \"Extract to JSON: The applicant has requested Department of the Army authorization to clear, grade and fill in order to expand an ex isting sand and gravel mining operation in Grangeville, Louisian a.The proposed sand and gra vel pits will encompass approximately 56.5 ac res and will be dug to adepth of 35 feet with 3:1 side slopes.Approximately 47,430 cubic yards of dirt, sand and gravel will be excavated and placed on upland areas of the site.It is anticipated that the proposed activity will impact approximately 1.47 acres of forested wetlands.It is presumed that the applicant has designed the project to a void and minimize direct and secondary adverse impacts tothe maximum extent practicable .As compensation forunavoidable wetland impacts, the applicant proposes to mitigatein-kind wetland credits from a Corps approved mitigat ion bank located in the watershed.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=600)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "439a3cd68d8841ba8d25e06df00d1e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4adf470dfa0f49c48c53064a865bcb5a",
              "IPY_MODEL_a20123a902f24f0bbc397b9cbac8eebb",
              "IPY_MODEL_afb1e86da43e47258a9ef6ebdbc6aa39"
            ],
            "layout": "IPY_MODEL_40e78802b4f74370b0dc995b0dee84c2"
          }
        },
        "4adf470dfa0f49c48c53064a865bcb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1ff7d15a0d4b2ea357ef183caa1202",
            "placeholder": "​",
            "style": "IPY_MODEL_cebff71a8c394a40a69b8e51480d7018",
            "value": "config.json: 100%"
          }
        },
        "a20123a902f24f0bbc397b9cbac8eebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0df51dc76a145ef902afbcba44186f2",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_762f6cd0abd74f0389c2c52959217443",
            "value": 571
          }
        },
        "afb1e86da43e47258a9ef6ebdbc6aa39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb88499d3c9455b8c76154859c91f36",
            "placeholder": "​",
            "style": "IPY_MODEL_0966b732e6a0437d8029f55f79f05b68",
            "value": " 571/571 [00:00&lt;00:00, 44.7kB/s]"
          }
        },
        "40e78802b4f74370b0dc995b0dee84c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1ff7d15a0d4b2ea357ef183caa1202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cebff71a8c394a40a69b8e51480d7018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0df51dc76a145ef902afbcba44186f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762f6cd0abd74f0389c2c52959217443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbb88499d3c9455b8c76154859c91f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0966b732e6a0437d8029f55f79f05b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129c92aea36a4837ae904cf52dfe63c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f7ab46f77b540baaec090601ea4aa4d",
              "IPY_MODEL_8fa0ccf77c6347fc8d62d835eef6df49",
              "IPY_MODEL_ac62c6ddbd0f48e0b036cf5c6eeaeb82"
            ],
            "layout": "IPY_MODEL_e33461eeaaab4a26ae54133d94f70ec2"
          }
        },
        "1f7ab46f77b540baaec090601ea4aa4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3885c0919e74436a8a5f29202212750d",
            "placeholder": "​",
            "style": "IPY_MODEL_bdbcbac8af93406d91b857fefb6e998b",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "8fa0ccf77c6347fc8d62d835eef6df49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c98ad0f76548689e61bf41091f3830",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95c8b3e71bd747c8a360a0015157acd5",
            "value": 25125
          }
        },
        "ac62c6ddbd0f48e0b036cf5c6eeaeb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446d79e223554d778f81927d1d8627b1",
            "placeholder": "​",
            "style": "IPY_MODEL_136d148dd6e940b0ab8af675d832f53e",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 2.32MB/s]"
          }
        },
        "e33461eeaaab4a26ae54133d94f70ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3885c0919e74436a8a5f29202212750d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdbcbac8af93406d91b857fefb6e998b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54c98ad0f76548689e61bf41091f3830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c8b3e71bd747c8a360a0015157acd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "446d79e223554d778f81927d1d8627b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136d148dd6e940b0ab8af675d832f53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d20fd6e4433d4dc8ab9199ccfd5b57a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61a4d79e24284d80b4659b8ff9faef8a",
              "IPY_MODEL_73f7f15a68964bbf8fcb5a3404536cb2",
              "IPY_MODEL_d770d4c60fad48ffa9dc45f7e7998490"
            ],
            "layout": "IPY_MODEL_455a847eea3d4890880d0c803764f8b7"
          }
        },
        "61a4d79e24284d80b4659b8ff9faef8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeba22ca47b84e138b7a191d82b19f63",
            "placeholder": "​",
            "style": "IPY_MODEL_ca8be5f63af7420583d9924fc05f7cc7",
            "value": "Downloading shards:   0%"
          }
        },
        "73f7f15a68964bbf8fcb5a3404536cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497f6ff3e2f14917be79e5eadee8a12f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_730d5fcc33ca4a829228f7fdbfbef425",
            "value": 0
          }
        },
        "d770d4c60fad48ffa9dc45f7e7998490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d5a01145be4b89986f847626928b76",
            "placeholder": "​",
            "style": "IPY_MODEL_d60b941f5265473d8fb865e46237260c",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "455a847eea3d4890880d0c803764f8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeba22ca47b84e138b7a191d82b19f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8be5f63af7420583d9924fc05f7cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497f6ff3e2f14917be79e5eadee8a12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730d5fcc33ca4a829228f7fdbfbef425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55d5a01145be4b89986f847626928b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60b941f5265473d8fb865e46237260c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30493cd8c368464885ac8b600353a56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e4b4676db2f460d934ce9727976705f",
              "IPY_MODEL_a5be4378fc6e4b4f98396d11b4d76930",
              "IPY_MODEL_a9bea130bee14529ad72163dc244ea5e"
            ],
            "layout": "IPY_MODEL_1cc27b234aa54f5f860f4ebbb54e9477"
          }
        },
        "6e4b4676db2f460d934ce9727976705f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42218085e56e490995412d663c6fe955",
            "placeholder": "​",
            "style": "IPY_MODEL_0083cb563a1b4100871321a06176f802",
            "value": "model-00001-of-00002.safetensors:  92%"
          }
        },
        "a5be4378fc6e4b4f98396d11b4d76930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f6e7ac443b4a70a17395f588bfdaa9",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_238a60a50c8c4193a3fba0c5581a8a7f",
            "value": 9101639680
          }
        },
        "a9bea130bee14529ad72163dc244ea5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6802efe69cc443a09f7facfb4cee9ce6",
            "placeholder": "​",
            "style": "IPY_MODEL_ec98fe8d7b104ad0bd444e8955b7d5b6",
            "value": " 9.10G/9.94G [03:03&lt;00:14, 56.3MB/s]"
          }
        },
        "1cc27b234aa54f5f860f4ebbb54e9477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42218085e56e490995412d663c6fe955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0083cb563a1b4100871321a06176f802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f6e7ac443b4a70a17395f588bfdaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238a60a50c8c4193a3fba0c5581a8a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6802efe69cc443a09f7facfb4cee9ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec98fe8d7b104ad0bd444e8955b7d5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}