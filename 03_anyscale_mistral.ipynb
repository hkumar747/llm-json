{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON outputs in Anyscale\n",
    "\n",
    "### Function Calling and JSON mode\n",
    "\n",
    "\n",
    "https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnyScale APIs\n",
    "\n",
    "https://docs.endpoints.anyscale.com/\n",
    "\n",
    "AnyScale is based off Ray\n",
    "https://thenewstack.io/how-ray-a-distributed-ai-framework-helps-power-chatgpt/\n",
    "\n",
    "\n",
    "Anyscale Endpoints offers the best open-source large language models (LLMs) as fully managed API endpoints. This allows you to focus on building applications powered by LLMs without the need to worry about the underlying infrastructure.\n",
    "\n",
    "\n",
    "### Testing it out - define client credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\Work\\Georgetown\\acad\\mdi\\final_portfolio\\llm-json')\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key = \"ESECRET\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. \"Chi dorme non piglia pesci\" (He who sleeps doesn't catch any fish) - This quote is attributed to Leonardo da Vinci and is often used to encourage people to stay awake and be productive. It suggests that opportunities and successes can be missed if one is not actively working towards them.\n",
      "2. \"La vita è bella\" (Life is beautiful) - This quote is a popular Italian expression that is often used to convey a sense of joy and appreciation for life. It is a reminder to cherish the present moment and to find beauty in the world around us.\n",
      "3. \"Non ci sono problemi, solo opportunità\" (There are no problems, only opportunities) - This quote is often attributed to Italian entrepreneur and inventor, Corrado Abbiati. It suggests that challenges and obstacles can be viewed as opportunities for growth and innovation.\n",
      "4. \"La dolce vita\" (The sweet life) - This phrase is often used to describe the Italian way of life, which is characterized by good food, wine, and relaxation. It is a reminder to enjoy the simple pleasures in life and to find happiness in the present moment.\n",
      "5. \"Meglio un giorno da leone che cento da pecora\" (Better one day as a lion than a hundred as a sheep) - This quote is often used to encourage people to take risks and pursue their passions. It suggests that it is better to live a short, fulfilling life than a long, unfulfilling one.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Write 5 famous quotes in Italian with explanations in english\"\n",
    "system_prompt=\"You are a helpful assistant.\"\n",
    "\n",
    "# Note: not all arguments are currently supported and will be ignored by the backend.\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "              {\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0.1\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USACE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =  \"\"\"\n",
    "    \"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\n",
    "\n",
    "    JSON Schema Overview:\n",
    "\n",
    "    wetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\n",
    "    impact_quantity: Numeric value of the impacted area.\n",
    "    impact_unit: Units of measurement (acres, sq. feet, linear feet).\n",
    "    impact_duration: Duration of impact (permanent, temporary, unknown).\n",
    "    impact_type: Nature of impact (harmful, beneficial, unknown).\n",
    "    Instructions:\n",
    "\n",
    "    Identify Wetlands and Impacts: Look for sentences detailing the wetland type and area impacted. Record the type, quantity, and unit.\n",
    "    Determine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\n",
    "    Assess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\n",
    "    Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\n",
    "    Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\n",
    "    Example Input:\n",
    "    'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...'\n",
    "\n",
    "    Expected Output:\n",
    "    {'wetlands': [{'wetland_type': 'marshland', 'impact_quantity': '3.5', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\n",
    "\n",
    "    Here is the text:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'This project would place approximat ely 855 cubic yards of commercially obtained fill material within 23,087 square feet (0. 53 acres) of wetlands for phase II of a single-family housing subdivision, which would include utility installation, access roads, building pads, and bank stabilization.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text passage:\n",
    "\n",
    ">>'This project would place approximately 855 cubic yards of commercially obtained fill material within 23,087 square feet (0. 53 acres) \n",
    ">> of wetlands for phase II of a \n",
    ">> single-family housing subdivision, which would include utility installation, access roads, building pads, and bank stabilization.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral 8x7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided text, here is the structured dictionary:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"wetlands\": [\n",
      "    {\n",
      "      \"wetland_type\": \"wetlands\",\n",
      "      \"impact_quantity\": \"0.53\",\n",
      "      \"impact_unit\": \"acres\",\n",
      "      \"impact_duration\": \"unknown\",\n",
      "      \"impact_type\": \"harmful\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "- Wetland Type: The text mentions that fill material will be placed within 23,087 square feet (0.53 acres) of wetlands. However, it does not specify the type of wetland, so we use \"wetlands\" as the type.\n",
      "- Impact Quantity: The text states that the impact is within 23,087 square feet, which is equivalent to 0.53 acres.\n",
      "- Impact Unit: The unit of measurement is acres, as stated in the text.\n",
      "- Impact Duration: The text does not provide information on the duration of the impact, so we use \"unknown\".\n",
      "- Impact Type: The text mentions that this project would affect the wetlands, implying harm. Therefore, we use \"harmful\" as the impact type.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key = \"ESECRET\"\n",
    ")\n",
    "# Note: not all arguments are currently supported and will be ignored by the backend.\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "              {\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0.1\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported models\n",
    "\n",
    "\n",
    "\n",
    "- **google-gemma-7b-it**\n",
    "- **meta-llama/Llama-2-7b-chat-hf**\n",
    "- **meta-llama/Llama-2-13b-chat-hf**\n",
    "- **meta-llama/Llama-2-70b-chat-hf**\n",
    "- **codellama/CodeLlama-70b-Instruct-hf**\n",
    "- **mistralai/Mistral-7B-Instruct-v0.1** - JSON mode support\n",
    "This instruction model is based on Mistral-7B-v0.1, a transformer model with the following architecture choices:\n",
    "\n",
    "Grouped-Query Attention\n",
    "Sliding-Window Attention\n",
    "Byte-fallback BPE tokenizer\n",
    "- **mistralai/Mixtral-8x7B-Instruct-v0.1**- JSON mode support\n",
    "- **mlabonne/NeuralHermes-2.5-Mistral-7B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON mode\n",
    "\n",
    "https://docs.endpoints.anyscale.com/text-generation/json-mode\n",
    "\n",
    "https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic example\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "api_base = os.getenv(\"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key = \"ESECRET\"\n",
    "token = os.getenv(\"OPENAI_API_KEY\")\n",
    "url = f\"{api_base}/chat/completions\"\n",
    "body = {\n",
    "    \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that outputs in JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020\"}\n",
    "    ],\n",
    "    \"response_format\": {\n",
    "        \"type\": \"json_object\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team_name\": {\"type\": \"string\"}\n",
    "            },\n",
    "            \"required\": [\"team_name\"]\n",
    "        },\n",
    "    },\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "with s.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body) as resp:\n",
    "    print(resp.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' {\\n\"wetlands\": [\\n{\\n\"wetland_type\": \"Commercially obtained fill material\",\\n\"impact_quantity\": 855,\\n\"impact_unit\": \"cubic yards\",\\n\"impact_duration\": \"unknown\",\\n\"impact_type\": \"Harmful\"\\n}\\n]\\n}'\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "\n",
    "# Setup the OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key = \"ESECRET\"\n",
    ")\n",
    "\n",
    "# Define the schema for the output based on your JSON structure\n",
    "class WetlandImpact(BaseModel):\n",
    "    wetland_type: str = Field(description=\"Type or descriptor of the wetland/water\")\n",
    "    impact_quantity: float = Field(description=\"Numeric value of the impacted area\")\n",
    "    impact_unit: str = Field(description=\"Units of measurement (mostly for area)\")\n",
    "    impact_duration: str = Field(description=\"Duration of impact\")\n",
    "    impact_type: str = Field(description=\"Nature of impact\")\n",
    "\n",
    "class Result(BaseModel):\n",
    "    wetlands: List[WetlandImpact] = Field(description=\"List of wetland impacts\")\n",
    "\n",
    "# Example system prompt and input text\n",
    "system_prompt = \"\"\"\n",
    "\"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. \n",
    "Focus on identifying wetland impacts based on the given schema. Some JSONs may contain multiple wetlands.\n",
    "\n",
    "JSON Schema Overview:\n",
    "\n",
    "wetland_type: Type or descriptor of the wetland.\n",
    "impact_quantity: Numeric value of the impacted area.\n",
    "impact_unit: Units of measurement (acres, sq. feet, linear feet).\n",
    "impact_duration: Duration of impact (permanent, temporary, unknown).\n",
    "impact_type: Nature of impact (dredging, loss etc).\n",
    "Instructions:\n",
    "\n",
    "Identify Wetlands and Impacts: Look for sentences detailing the wetland type and area impacted. Record the type, quantity, and unit.\n",
    "Determine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\n",
    "Assess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\n",
    "Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\n",
    "Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Make a request to generate a completion\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    response_format={\n",
    "        \"type\": \"json_object\", \n",
    "        \"schema\": Result.schema_json()\n",
    "    },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the text: {query}\"}\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Print the structured output\n",
    "response_json = repr(chat_completion.choices[0].message.content)\n",
    "\n",
    "print (response_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning open LLMs\n",
    "\n",
    "### \"Fine-tuning is for form, not facts\"\n",
    "https://docs.endpoints.anyscale.com/examples/e2e-finetune-and-serve-example/\n",
    "\n",
    "AnyScale is built to work as seamlessly possible with OpenAI, so it takes the finetuning examples file in the same `.jsonl` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "training_file_id = client.files.create(\n",
    "    file=open('data/usace_finetune_training.jsonl','rb'),\n",
    "    purpose=\"fine-tune\",\n",
    ").id\n",
    "\n",
    "valid_file_id = client.files.create(\n",
    "    file=open('data/usace_finetune_validation.jsonl','rb'),\n",
    "    purpose=\"fine-tune\",\n",
    ").id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function and run over multiple models\n",
    "\n",
    "\n",
    "- Llama-2-13b-chat-hf\n",
    "\n",
    "- Mixtral-8x7B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model_name, train_file, val_file):\n",
    "\n",
    "    model = model_name\n",
    "    print(\"Creating finetuning job...\")\n",
    "    finetuning_job_id = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file,\n",
    "    validation_file=val_file,\n",
    "    model=model).id\n",
    "\n",
    "    print(\"Finetuning job ID - \")\n",
    "    return finetuning_job_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"meta-llama/Llama-2-13b-chat-hf\"\n",
    "finetuning_job_id = client.fine_tuning.jobs.create(\n",
    "training_file=training_file_id,\n",
    "validation_file=valid_file_id,\n",
    "model=model).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating finetuning job...\n",
      "Finetuning job ID - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eftjob_a7gbaxryvjcqa42ruanrmpbgpt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixtral_ft_id =  finetune_model(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "                                train_file=training_file_id, \n",
    "                                val_file = valid_file_id)\n",
    "mixtral_ft_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='eftjob_v7t6ca93vg6jc425b12kbllkpv', created_at='2024-03-24T02:19:32.669376+00:00', error=None, fine_tuned_model='meta-llama/Llama-2-13b-chat-hf:eidc:2vyR4cT', finished_at='2024-03-24T02:32:51.990087+00:00', hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='meta-llama/Llama-2-13b-chat-hf', object=None, organization_id=None, result_files=['file_9c3lbpirf5di3j117psvvcrvky'], status='succeeded', trained_tokens=880590, training_file='file_c4w4dcvef2zsf3w1esblcxmdc1', validation_file='file_fyyq7t3me1p1az1kp1sd6f2sfw', creator_id='euser_p9pnrl49qhj84wahdslje29ymp')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(finetuning_job_id)\n",
    "\n",
    "#eftjob_v7t6ca93vg6jc425b12kbllkpv - JobID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='eftjob_a7gbaxryvjcqa42ruanrmpbgpt', created_at='2024-03-24T04:09:35.641413+00:00', error=None, fine_tuned_model='mistralai/Mixtral-8x7B-Instruct-v0.1:eidc:NfYTbEB', finished_at=None, hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='mistralai/Mixtral-8x7B-Instruct-v0.1', object=None, organization_id=None, result_files=[], status='running', trained_tokens=None, training_file='file_c4w4dcvef2zsf3w1esblcxmdc1', validation_file='file_fyyq7t3me1p1az1kp1sd6f2sfw', creator_id='euser_p9pnrl49qhj84wahdslje29ymp')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixtral\n",
    "client.fine_tuning.jobs.retrieve(mixtral_ft_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for email notification!\n",
    "\n",
    "\n",
    "The field `fine_tuned_model` contains the ID of our finetuned model version, which in this case is `meta-llama/Llama-2-13b-chat-hf:eidc:2vyR4cT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"result_files\": [\n",
    "        \"file_9c3lbpirf5di3j117psvvcrvky\"\n",
    "    ],\n",
    "    \"trained_tokens\": 880590,\n",
    "    \"hyperparameters\": {\n",
    "        \"n_epochs\": null,\n",
    "        \"context_length\": null\n",
    "    },\n",
    "    \"training_file\": \"file_c4w4dcvef2zsf3w1esblcxmdc1\",\n",
    "    \"validation_file\": \"file_fyyq7t3me1p1az1kp1sd6f2sfw\",\n",
    "    \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "    \"id\": \"eftjob_v7t6ca93vg6jc425b12kbllkpv\",\n",
    "    \"created_at\": \"2024-03-24 02:19:32.669376+00:00\",\n",
    "    \"finished_at\": \"2024-03-24 02:32:36.662632+00:00\",\n",
    "    \"fine_tuned_model\": \"meta-llama/Llama-2-13b-chat-hf:eidc:2vyR4cT\",\n",
    "    \"status\": \"succeeded\",\n",
    "    \"error\": null,\n",
    "    \"creator_id\": \"euser_p9pnrl49qhj84wahdslje29ymp\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"'The applicant seeks authorization to dredge and fill material into 3.23 acres of waters of the United States (wetlands) for the development of phase 5 of the of Storey Grove residential development .'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'The proposed modifications would be accomplished by widening the inside and outside of the existing roadway and replacing the westbound SR 528 bridge over the Indian River. Stormwater w ould be conveyed to treatment ponds which w ould be designed for the 6 -lane roadway. The proposed project would directly impact 2.14 acres of forested wetlands, 0.84 acres of surface waters and 2.8 8 acres of roadside ditches and other surface waters associated with the Indian River by the placement of 7,031 cubic yards of fill and dredging 179 cubic yards of material . Temporary impacts associated with this project would include impacts to 0.11 acres of forested wetlands and 0.002 acre of surface waters.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'wetlands': [{'wetland_type': 'forested wetlands', 'impact_quantity': '2.14', 'impact_unit': 'acres', 'impact_duration': 'direct', 'impact_type': 'loss'}, {'wetland_type': 'surface waters', 'impact_quantity': '0.84', 'impact_unit': 'acres', 'impact_duration': 'direct', 'impact_type': 'loss'}, {'wetland_type': 'roadside ditches and other surface waters', 'impact_quantity': '2.88', 'impact_unit': 'acres', 'impact_duration': 'direct', 'impact_type': 'loss'}, {'wetland_type': 'forested wetlands', 'impact_quantity': '0.11', 'impact_unit': 'acres', 'impact_duration': 'temporary', 'impact_type': 'loss'}, {'wetland_type': 'surface waters', 'impact_quantity': '0.002', 'impact_unit': 'acre', 'impact_duration': 'temporary', 'impact_type': 'loss'}]} \n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key = \"ESECRET\"\n",
    ")\n",
    "# Note: not all arguments are currently supported and will be ignored by the backend.\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-2-13b-chat-hf:eidc:2vyR4cT\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "              {\"role\": \"user\", \"content\": text2}],\n",
    "    temperature=0.0\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated count checker - function?\n",
    "\n",
    "We have a set of 174 passages for which\n",
    "\n",
    "\n",
    "### Non-deterministic outputs:\n",
    "\n",
    "Yeah, there doesn't seem to be an easy way out of this one. Unlike simulations in the energy domain, we cannot run thousands of scenarios while billed on the basis of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
